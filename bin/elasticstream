#!/usr/bin/env python

import os
import sys
import argparse
import json
import time

########################################################################################################################
# allow this script to be run from bin dir without install
########################################################################################################################
try:
    from elasticstream import ElasticStream
except ImportError:
    path = os.path.abspath(sys.argv[0])
    while os.path.dirname(path) != path:
        if os.path.exists(os.path.join(path, 'elasticstream', '__init__.py')):
            sys.path.insert(0, path)
            break
        path = os.path.dirname(path)
    from elasticstream import ElasticStream
########################################################################################################################

parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('-u', '--url', help='Elasticsearch REST endpoint URL', default='localhost:9200')
parser.add_argument('-i', '--index', help='Elasticsearch index to stream (wildcards allowed)', default='*')
parser.add_argument('-k', '--keepalive', help='Duration to keep scroll alive. Tune according to --size', default='1m')
parser.add_argument('-s', '--size', help='Number of hits to scroll at once. Tune according to sharding', default='10')
parser.add_argument('-d', '--dsl', help='Elasticsearch DSL query or @file (e.g., "curl -d" syntax) containing query',
                    default='{"query": {"match_all": {}}}')
parser.add_argument('-f', '--format', choices=['ndjson', 'csv'], help='Output format. Newline-delimited JSON or CSV',
                    default='ndjson')
parser.add_argument('-o', '--output', help='Output file to stream to. If not stdout, prints progress to stdout',
                    default=sys.__stdout__)
args = parser.parse_args()

# allow curl -d @syntax
if args.dsl.startswith('@'):
    with open(args.dsl[1:]) as f:
        args.dsl = json.dumps(json.load(f))

# open the file once. we will flush periodically
if args.output is not sys.__stdout__:
    args.output = open(str(args.output), 'w')

stream = ElasticStream(args.url, args.index, args.dsl, scroll_keepalive=args.keepalive, scroll_size=args.size)
start_time = time.time()
start_hits = 0

try:
    # headers
    if args.format == 'csv':
        args.output.write(','.join(stream.mappings)+'\n')

    for hit in stream:
        # see http://ndjson.org/ for more info
        if args.format == 'ndjson':
            args.output.write(json.dumps(hit['_source'])+'\n')
            args.output.flush()

        # csv is slightly more complicated. need to keep track of headers and quote strings
        elif args.format == 'csv':
            # sort hit in header order
            hit_list = []
            for mapping in stream.mappings:
                if mapping in hit['_source']:
                    if stream.mappings[mapping]['type'] == 'string':
                        hit_list.append('"%s"' % hit['_source'][mapping])  # quote string just in case
                    else:
                        hit_list.append(str(hit['_source'][mapping]))
                else:
                    hit_list.append('')  # missing data
            args.output.write(','.join(hit_list)+'\n')
            args.output.flush()

        # if aren't streaming to stdout, we can print progress
        if args.output is not sys.__stdout__ and stream.hits_scrolled % int(args.size) == 0:
            elapsed_time = time.time() - start_time
            elapsed_hits = stream.hits_scrolled - start_hits
            start_time = time.time()
            start_hits = stream.hits_scrolled

            sys.stdout.write('   %d/%d hits (%f/sec)   \r'
                             % (stream.hits_scrolled, stream.hits_total, elapsed_hits/elapsed_time))
            sys.stdout.flush()
            time.sleep(0.1)

except KeyboardInterrupt:
    pass

finally:
    args.output.close()
    if args.output is not sys.__stdout__:
        sys.stdout.write('\n')
        sys.stdout.flush()
